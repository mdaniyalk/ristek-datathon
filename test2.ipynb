{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost\n",
    "import scipy.stats as stats\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import ephem\n",
    "\n",
    "from utils import smape, plot_eval\n",
    "\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    df = df.drop(['lanes', 'lanes:forward', 'lit'], axis=1)\n",
    "\n",
    "    unique_maxspeed = df['maxspeed'].unique()\n",
    "    max_speed = []\n",
    "    for data in tqdm(df['maxspeed'].to_numpy(), desc='Convert to kph'):\n",
    "        if data == '30 mph':\n",
    "            max_speed.append(48.2803)\n",
    "        elif data == '20 mph':\n",
    "            max_speed.append(32.1869)\n",
    "\n",
    "    df['maxspeed'] = max_speed\n",
    "    \n",
    "    is_weekend = []\n",
    "    is_night = []\n",
    "    is_rush_hour = []\n",
    "    date = []\n",
    "    hour = []\n",
    "\n",
    "    uk_observer = ephem.Observer()\n",
    "    uk_observer.lat = '51.5074'  # Latitude of London\n",
    "    uk_observer.lon = '-0.1278'  # Longitude of London\n",
    "\n",
    "\n",
    "    for data in tqdm(df['waktu_setempat'].to_numpy(), desc='time categorization'):\n",
    "        datetime_obj = datetime.strptime(data, '%Y-%m-%d %H:%M:%S%z')\n",
    "        day_of_week = datetime_obj.weekday()\n",
    "        if day_of_week >= 5:\n",
    "            is_weekend.append(1)\n",
    "        else:\n",
    "            is_weekend.append(0)\n",
    "        date_component = datetime_obj.strftime('%Y-%m-%d')\n",
    "        hour_component = datetime_obj.strftime('%H')\n",
    "        date.append(date_component)\n",
    "        hour.append(int(hour_component))\n",
    "        # Set the observer's date and time to the input UTC time\n",
    "        uk_observer.date = datetime_obj\n",
    "\n",
    "        # Calculate sunrise and sunset times\n",
    "        sunrise = uk_observer.previous_rising(ephem.Sun())\n",
    "        sunset = uk_observer.next_setting(ephem.Sun())\n",
    "        if sunrise < uk_observer.date < sunset:\n",
    "            is_night.append(0)\n",
    "        else:\n",
    "            is_night.append(1)\n",
    "        \n",
    "        # Define the time ranges\n",
    "        morning_rush_hour_start = datetime.strptime('10:00:00', '%H:%M:%S').time()\n",
    "        morning_rush_hour_end = datetime.strptime('16:00:00', '%H:%M:%S').time()\n",
    "\n",
    "        night_rush_hour_start = datetime.strptime('20:00:00', '%H:%M:%S').time()\n",
    "        night_rush_hour_end = datetime.strptime('23:59:59', '%H:%M:%S').time()\n",
    "\n",
    "        night_rush_hour_start_2 = datetime.strptime('00:00:00', '%H:%M:%S').time()\n",
    "        night_rush_hour_end_2 = datetime.strptime('06:00:00', '%H:%M:%S').time()\n",
    "\n",
    "        # Extract the time component from the input datetime object\n",
    "        input_time = datetime_obj.time()\n",
    "\n",
    "        # Check if the time falls within the desired ranges\n",
    "        if morning_rush_hour_start <= input_time <= morning_rush_hour_end or (night_rush_hour_start <= input_time <= night_rush_hour_end) or (night_rush_hour_start_2 <= input_time <= night_rush_hour_end_2):\n",
    "            is_rush_hour.append(1)\n",
    "        else:\n",
    "            is_rush_hour.append(0)\n",
    "\n",
    "    df['is_weekend'] = is_weekend\n",
    "    df['hour'] = hour\n",
    "    df['date'] = date\n",
    "    df['is_night'] = is_night\n",
    "    df['is_rush_hour'] = is_rush_hour\n",
    "    df = df.drop(['waktu_setempat'], axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qq(data1, data2):\n",
    "    sorted_data1 = np.sort(data1)\n",
    "    sorted_data2 = np.sort(data2)\n",
    "    n = len(sorted_data1)\n",
    "    quantiles1 = np.arange(1, n + 1) / n\n",
    "    quantiles2 = np.arange(1, n + 1) / n\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(sorted_data1, sorted_data2)\n",
    "    plt.xlabel(\"Data rerata_kecepatan tanggal 2020-02-01\")\n",
    "    plt.ylabel(\"Data rerata_kecepatan tanggal 2020-02-02\")\n",
    "    plt.title(\"QQ Plot antara Data rerata_kecepatan tanggal 2020-02-01 dan 2020-02-02\")\n",
    "    plt.plot([min(sorted_data1), max(sorted_data1)], [min(sorted_data1), max(sorted_data1)], color='red', linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in df['date'].unique():\n",
    "    print(df[df['date'] == date].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['date'] == '2020-02-01']['rerata_kecepatan'].to_numpy().shape\n",
    "df[df['date'] == '2020-02-06']['rerata_kecepatan'].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_qq(df[df['date'] == '2020-02-01']['rerata_kecepatan'].to_numpy(), df[df['date'] == '2020-02-02']['rerata_kecepatan'].to_numpy()[:19827])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id_jalan', 'id_titik_mulai', 'id_titik_akhir', 'date', 'rerata_kecepatan'], axis=1)\n",
    "y = df['rerata_kecepatan'].to_numpy()\n",
    "# max_speed = y.max() * 1.2\n",
    "# y = y / max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBRegressor(n_jobs=-1, random_state=42)\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "print(f'test_data: {smape(y_test, pred)}')\n",
    "plot_eval(pred*max_speed, y_test*max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train)\n",
    "print(f'train_data: {smape(y_train, pred)}')\n",
    "plot_eval(pred*max_speed, y_train*max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1000, 5000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-1, log=True)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.1, 1.0, step=0.1)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 7, step=2)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0, step=0.1)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0., 1.0, step=0.1)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0., 1.0, step=0.1)\n",
    "    seed = trial.suggest_int(\"random_state\", 20, 50, step=2)\n",
    "    \n",
    "    \n",
    "    model = xgboost.XGBRegressor(n_estimators=n_estimators,\n",
    "                                max_depth=max_depth,\n",
    "                                learning_rate=learning_rate,\n",
    "                                gamma=gamma,\n",
    "                                min_child_weight=min_child_weight,\n",
    "                                colsample_bytree=colsample_bytree,\n",
    "                                subsample=subsample,\n",
    "                                reg_alpha=reg_alpha,\n",
    "                                reg_lambda=reg_lambda,\n",
    "                                n_jobs=-1, metric=mean_squared_error,\n",
    "                                eval_metric=mean_squared_error,\n",
    "                                random_state=seed\n",
    "                                )\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(x_test)\n",
    "    \n",
    "    return mean_squared_error(y_test, y_hat, squared=True)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I 2023-08-10 13:54:53,556] Trial 28 finished with value: 12.492314534341407 and parameters: {'n_estimators': 1587, 'max_depth': 8, 'learning_rate': 0.0415545742214241, 'gamma': 0.6, 'min_child_weight': 3, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.0, 'reg_lambda': 0.9, 'random_state': 28}. Best is trial 28 with value: 12.492314534341407.\n",
    "[I 2023-08-10 04:37:44,166] Trial 32 finished with value: 12.503876898303945 and parameters: {'n_estimators': 2830, 'max_depth': 8, 'learning_rate': 0.02149679605911237, 'gamma': 0.1, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.6000000000000001, 'random_state': 42}. Best is trial 32 with value: 12.503876898303945.\n",
    "[I 2023-08-10 05:53:02,056] Trial 42 finished with value: 12.490182406993412 and parameters: {'n_estimators': 3888, 'max_depth': 7, 'learning_rate': 0.024530410097984914, 'gamma': 0.1, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.6000000000000001, 'reg_lambda': 0.5, 'random_state': 42}. Best is trial 42 with value: 12.490182406993412.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    \n",
    "    subsample_for_bin = trial.suggest_int(\"subsample_for_bin\", 100000, 300000)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1000, 5000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-1, log=True)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 10, 50)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 7, step=2)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0, step=0.1)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0., 1.0, step=0.1)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0., 1.0, step=0.1)\n",
    "    seed = trial.suggest_int(\"random_state\", 20, 50, step=2)\n",
    "    min_child_samples = trial.suggest_int(\"min_child_samples\", 10, 50)\n",
    "    \n",
    "    model = lgb.LGBMRegressor(num_leaves=num_leaves, max_depth=max_depth, learning_rate=learning_rate, \n",
    "                              n_estimators=n_estimators, subsample_for_bin=subsample_for_bin, \n",
    "                              min_child_weight=min_child_weight, min_child_samples=min_child_samples, subsample=subsample, \n",
    "                              colsample_bytree=colsample_bytree, reg_alpha=reg_alpha, \n",
    "                              reg_lambda=reg_lambda, random_state=seed, n_jobs=-1,)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(x_test)\n",
    "    \n",
    "    return mean_squared_error(y_test, y_hat, squared=True)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I 2023-08-09 16:50:04,570] Trial 78 finished with value: 12.534454690626298 and parameters: {'subsample_for_bin': 155546, 'n_estimators': 3768, 'max_depth': 7, 'learning_rate': 0.04067420520019853, 'num_leaves': 50, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.5, 'reg_lambda': 0.30000000000000004, 'random_state': 34, 'min_child_samples': 16}. Best is trial 78 with value: 12.534454690626298.\n",
    "[I 2023-08-09 16:58:36,247] Trial 93 finished with value: 12.533047460664628 and parameters: {'subsample_for_bin': 131673, 'n_estimators': 4510, 'max_depth': 6, 'learning_rate': 0.054834260577325884, 'num_leaves': 47, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 0.30000000000000004, 'random_state': 34, 'min_child_samples': 16}. Best is trial 93 with value: 12.533047460664628.\n",
    "[I 2023-08-10 10:37:54,202] Trial 153 finished with value: 12.532367782002835 and parameters: {'subsample_for_bin': 150438, 'n_estimators': 2301, 'max_depth': 10, 'learning_rate': 0.06770102677206172, 'num_leaves': 49, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 0.8, 'random_state': 38, 'min_child_samples': 26}. Best is trial 153 with value: 12.532367782002835.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {}\n",
    "    param['learning_rate'] = trial.suggest_float(\"learning_rate\", 1e-6, 1e-1, log=True)\n",
    "    param['depth'] = trial.suggest_int('depth', 9, 15)\n",
    "    param['l2_leaf_reg'] = trial.suggest_float(\"l2_leaf_reg\", 0., 1.0, step=0.1)\n",
    "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
    "    param['grow_policy'] = 'Depthwise'\n",
    "    param['iterations'] = trial.suggest_int(\"iterations\", 1000, 5000)\n",
    "    param['loss_function'] = 'RMSE'\n",
    "\n",
    "    param['random_state'] = trial.suggest_int(\"random_state\", 20, 50, step=2)\n",
    "    param['logging_level'] = 'Silent'\n",
    "    \n",
    "    model = CatBoostRegressor(**param)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(x_test)\n",
    "    \n",
    "    return mean_squared_error(y_test, y_hat, squared=True)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_1(no):\n",
    "  param_1 = {'n_estimators': 2552, 'max_depth': 9, 'learning_rate': 0.010419707354527082, 'gamma': 0.30000000000000004, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.30000000000000004, 'reg_lambda': 0.5, 'random_state': 28}\n",
    "\n",
    "  param_2 = {'n_estimators': 4627, 'max_depth': 10, \n",
    "             'learning_rate': 0.03031698197768738, \n",
    "             'gamma': 0.7000000000000001, 'min_child_weight': 7, \n",
    "             'subsample': 0.9, 'colsample_bytree': 1.0, \n",
    "             'reg_alpha': 0.30000000000000004, \n",
    "             'reg_lambda': 0.30000000000000004, \n",
    "             'random_state': 22, 'grow_policy' : 'depthwise', \n",
    "            'n_jobs' : -1}\n",
    "  \n",
    "  params = [param_1, param_2]\n",
    "  xgb = xgboost.XGBRegressor(**params[no])\n",
    "  return xgb\n",
    "\n",
    "def lgbm_1(no):\n",
    "  param_1 = {'subsample_for_bin': 131673, 'n_estimators': 4510, 'max_depth': 6, 'learning_rate': 0.054834260577325884, 'num_leaves': 47, 'min_child_weight': 1, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.7000000000000001, 'reg_lambda': 0.30000000000000004, 'random_state': 34, 'min_child_samples': 16}\n",
    "\n",
    "  param_2 = {'subsample_for_bin': 155546, 'n_estimators': 3768, 'max_depth': 7, 'learning_rate': 0.04067420520019853, 'num_leaves': 50, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.5, 'reg_lambda': 0.30000000000000004, 'random_state': 34, 'min_child_samples': 16}\n",
    "  \n",
    "  params = [param_1, param_2]\n",
    "  lgbm = lgb.LGBMRegressor(**params[no])\n",
    "  return lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators1 = [('xgb_1{}'.format(i), xgb_1(i)) for i in range(1)]\n",
    "estimators2 = [('lgbm_1{}'.format(j), lgbm_1(j))  for j in range(2)]\n",
    "estimators = estimators1+estimators2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in estimators:\n",
    "    name, reg = est\n",
    "    print(f'Evaluating {name} model')\n",
    "    reg.fit(x_train, y_train)\n",
    "    pred = reg.predict(x_test)\n",
    "    print(f'test_data: {smape(y_test, pred)}')\n",
    "    pred = reg.predict(x_train)\n",
    "    print(f'train_data: {smape(y_train, pred)}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = StackingRegressor(estimators=estimators, cv=3, final_estimator=LinearRegression(n_jobs=-1), n_jobs = -1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('stack_model_submission-2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.load(open(\"stack_model_submission-2.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "print(f'test_data: {smape(y_test, pred)}')\n",
    "plot_eval(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train)\n",
    "print(f'train_data: {smape(y_train, pred)}')\n",
    "plot_eval(pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('new_test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = prepare_data(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X.columns\n",
    "data_test = df_test[cols]\n",
    "\n",
    "\n",
    "pred_test = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('submissionV2.csv')\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm['rerata_kecepatan'] = pred_test\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('submission-new_data-v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
