{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import smape\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f'column: {col}; n_unique: {df[col].unique().shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_titik = np.sort(np.unique(np.concatenate((df['id_titik_mulai'].unique(), df['id_titik_akhir'].unique()), axis=0)), axis=0, kind='mergesort')\n",
    "id_jalan = np.sort(df['id_jalan'].unique(), axis=0, kind='mergesort')\n",
    "waktu_setempat = np.sort(df['waktu_setempat'].unique(), axis=0, kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['waktu_setempat','id_jalan', 'id_titik_mulai', 'id_titik_akhir']\n",
    "for col in cols:\n",
    "    tmp = []\n",
    "    for data in df[col].to_numpy():\n",
    "        if col == 'id_jalan':\n",
    "            idx = np.where(id_jalan == data)\n",
    "            idx = idx[0][0] / id_jalan.shape[0]\n",
    "        elif col == 'waktu_setempat':\n",
    "            idx = np.where(waktu_setempat == data)\n",
    "            idx = idx[0][0]\n",
    "        else:\n",
    "            idx = np.where(id_titik == data)\n",
    "            idx = idx[0][0] / id_titik.shape[0]\n",
    "        tmp.append(idx)\n",
    "    df[col] = tmp\n",
    "tmp = df['rerata_kecepatan'].to_numpy()\n",
    "max_avg = df['rerata_kecepatan'].max() * 1.2\n",
    "df['rerata_kecepatan'] = tmp / max_avg\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, window_len, forecast_len):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    Y = []\n",
    "    no_prev = np.array([[-1, -1, -1, -1]]).astype(np.float32)\n",
    "    n_waktu_setempat = 527\n",
    "    n_jalan = 20\n",
    "    n_titik_mulai = 488\n",
    "    n_titik_akhir = 488\n",
    "    split_by_jalan = []\n",
    "    df = df.sort_values(by=['waktu_setempat', 'id_jalan', 'id_titik_mulai', 'id_titik_akhir'])\n",
    "    for i in range(n_jalan):\n",
    "        tmp = df[(df['id_jalan'] == i/20)]\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "        split_by_jalan.append(tmp)\n",
    "    for i in tqdm(range(n_jalan)):\n",
    "        data = split_by_jalan[i]\n",
    "        for t in range(n_waktu_setempat):\n",
    "            # for j in range(n_titik_mulai):\n",
    "            tmp = []\n",
    "            for k in range(window_len):\n",
    "                tmp2 = data[(data['waktu_setempat'] == t+k)]\n",
    "                tmp2 = tmp2.reset_index(drop=True)\n",
    "                tmp2 = tmp2.drop(['waktu_setempat'], axis=1)\n",
    "                tmp2 = tmp2.to_numpy().astype(np.float32)\n",
    "                tmp2 = np.concatenate((tmp2, no_prev), axis=0)\n",
    "                tmp.append(tmp2)\n",
    "            tmp2 = data[(data['waktu_setempat'] == t+window_len)]\n",
    "            tmp2 = tmp2.reset_index(drop=True)\n",
    "            tmp4 = tmp2['rerata_kecepatan'].to_numpy()\n",
    "            tmp2 = tmp2.drop(['waktu_setempat', 'rerata_kecepatan'], axis=1)\n",
    "            tmp2 = tmp2.to_numpy()\n",
    "            if window_len > 1:\n",
    "                tmp3 = list(itertools.product(*tmp))\n",
    "                \n",
    "            else:\n",
    "                tmp3 = tmp[0]\n",
    "            tmp3 = np.asarray(tmp3)\n",
    "            tmpX = []\n",
    "            tmpY = []\n",
    "            for _tmp in tmp3:\n",
    "                for idx, __tmp in enumerate(tmp2):\n",
    "                    _tmp = np.asarray(_tmp)\n",
    "                    __tmp = np.asarray(__tmp)\n",
    "                    __tmp2 = tmp4[idx]\n",
    "                    X.append(_tmp)\n",
    "                    X2.append(__tmp)\n",
    "                    Y.append(__tmp2)\n",
    "            # X.append(tmpX)\n",
    "            # Y.append(tmpY)\n",
    "            # X = X + tmpX\n",
    "            # Y = Y + tmpY\n",
    "\n",
    "    \n",
    "    # X = np.concatenate(X, axis=0)\n",
    "    # Y = np.concatenate(Y, axis=0)\n",
    "    X = np.asarray(X)\n",
    "    X2 = np.asarray(X2)\n",
    "    Y = np.asarray(Y)\n",
    "    return X, X2,  Y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp2 = tmp2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len=1\n",
    "forecast_len = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X2, Y = create_dataset(df, window_len=window_len, forecast_len=forecast_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, x2_train, x2_test, y_train, y_test = train_test_split(X, X2, Y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder_block(past_inputs, future_inputs):\n",
    "    # Encoding the past\n",
    "    encoder = tf.keras.layers.LSTM(128, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(past_inputs)\n",
    "    state_h = state_h + tf.keras.layers.Dense(128, activation='relu')(state_h)\n",
    "    state_c = state_c + tf.keras.layers.Dense(128, activation='relu')(state_c)\n",
    "    \n",
    "    # x = tf.keras.layers.Dense(1)(future_inputs)\n",
    "    # \n",
    "    # Combining future inputs with recurrent branch output\n",
    "    decoder_lstm = tf.keras.layers.LSTM(128, return_sequences=True)\n",
    "    x = decoder_lstm(future_inputs,\n",
    "                    initial_state=[state_h, state_c])\n",
    "    return x\n",
    "\n",
    "past_inputs = tf.keras.Input(\n",
    "    shape=(window_len, 4), name='past_inputs')\n",
    "future_inputs = tf.keras.Input(\n",
    "        shape=(forecast_len, 3), name='future_inputs')\n",
    "\n",
    "x_1 = encoder_decoder_block(past_inputs, future_inputs)\n",
    "x = tf.keras.layers.Dense(4, activation='linear')(x_1) + past_inputs\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = encoder_decoder_block(x, future_inputs)\n",
    "x_2 = tf.keras.layers.Dense(256, activation='relu')(future_inputs)\n",
    "x = tf.keras.layers.Concatenate(axis=2)([x, x_1, x_2])\n",
    "x_1 = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x_1)\n",
    "x = tf.keras.layers.Concatenate(axis=1)([x, x_1])\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "output = tf.keras.layers.LeakyReLU(alpha=1e-5, name='outputs')(output)\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[past_inputs, future_inputs], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_inputs = tf.keras.Input(\n",
    "    shape=(window_len, 4), name='past_inputs')\n",
    "# Encoding the past\n",
    "encoder = tf.keras.layers.LSTM(128, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(past_inputs)\n",
    "state_h = state_h + tf.keras.layers.Dense(128, activation='relu')(state_h)\n",
    "state_c = state_c + tf.keras.layers.Dense(128, activation='relu')(state_c)\n",
    "future_inputs = tf.keras.Input(\n",
    "    shape=(forecast_len, 3), name='future_inputs')\n",
    "# x = tf.keras.layers.Dense(1)(future_inputs)\n",
    "# \n",
    "# Combining future inputs with recurrent branch output\n",
    "decoder_lstm = tf.keras.layers.LSTM(128, return_sequences=True)\n",
    "x = decoder_lstm(future_inputs,\n",
    "                 initial_state=[state_h, state_c])\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "output = tf.keras.layers.LeakyReLU(alpha=1e-5, name='outputs')(output)\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[past_inputs, future_inputs], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def smape_loss(y_true, y_pred):\n",
    "    epsilon = 0.1\n",
    "    summ = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
    "    smape = K.abs(y_pred - y_true) / summ * 2.0\n",
    "    return smape\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "loss = tf.keras.losses.MeanAbsoluteError()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[\"mae\", 'mse', 'mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([np.expand_dims(x1_train, axis=1), np.expand_dims(x2_train, axis=1)], y_train, epochs=20, validation_split=0.2, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tmpx1 = []\n",
    "tmpx2 = []\n",
    "for idx, (x1, x2) in enumerate(zip(np.expand_dims(x1_test, axis=1), np.expand_dims(x2_test, axis=1))):\n",
    "    tmpx1.append(x1)\n",
    "    tmpx2.append(x2)\n",
    "    if (idx+1) % 2048000 == 0 or (idx+1) == len(x1_test):\n",
    "        tmpx1 = np.asarray(tmpx1)\n",
    "        tmpx2 = np.asarray(tmpx2)\n",
    "        tmp = model.predict([tmpx1, tmpx2], batch_size=2048)\n",
    "        tmp = np.asarray(tmp).astype(np.float32)\n",
    "        pred.append(tmp)\n",
    "        tmpx1 = []\n",
    "        tmpx2 = []\n",
    "pred = np.concatenate(pred, axis=0)\n",
    "pred = pred.flatten()\n",
    "print(f'test_data: {smape(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tmpx1 = []\n",
    "tmpx2 = []\n",
    "for idx, (x1, x2) in enumerate(zip(np.expand_dims(x1_train, axis=1), np.expand_dims(x2_train, axis=1))):\n",
    "    tmpx1.append(x1)\n",
    "    tmpx2.append(x2)\n",
    "    if (idx+1) % (2*4096000) == 0 or (idx+1) == len(x1_train):\n",
    "        tmpx1 = np.asarray(tmpx1)\n",
    "        tmpx2 = np.asarray(tmpx2)\n",
    "        tmp = model.predict([tmpx1, tmpx2], batch_size=4096)\n",
    "        tmp = np.asarray(tmp).astype(np.float32)\n",
    "        pred.append(tmp)\n",
    "        tmpx1 = []\n",
    "        tmpx2 = []\n",
    "pred = np.concatenate(pred, axis=0)\n",
    "pred = pred.flatten()\n",
    "print(f'train_data: {smape(y_train, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([np.expand_dims(x1_train, axis=1)[0:5], np.expand_dims(x2_train, axis=1)[0:5]]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['waktu_setempat','id_jalan', 'id_titik_mulai', 'id_titik_akhir']\n",
    "waktu_setempat_test = np.sort(df_test['waktu_setempat'].unique(), axis=0, kind='mergesort')\n",
    "for col in cols:\n",
    "    tmp = []\n",
    "    for data in df_test[col].to_numpy():\n",
    "        if col == 'id_jalan':\n",
    "            idx = np.where(id_jalan == data)\n",
    "            idx = idx[0][0] / id_jalan.shape[0]\n",
    "        elif col == 'waktu_setempat':\n",
    "            idx = np.where(waktu_setempat_test == data)\n",
    "            idx = idx[0][0]\n",
    "        else:\n",
    "            idx = np.where(id_titik == data)\n",
    "            idx = idx[0][0] / id_titik.shape[0]\n",
    "        tmp.append(idx)\n",
    "    df_test[col] = tmp\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(waktu_setempat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(df, df_test, model, max_avg):\n",
    "    last_data = df[(df['waktu_setempat'] == 526)]\n",
    "    last_data = last_data.reset_index(drop=True)\n",
    "    n_time = 168\n",
    "    predicted_data = {'id':[], 'rerata_kecepatan':[]}\n",
    "    no_prev = np.array([[-1, -1, -1, -1]]).astype(np.float32)\n",
    "    for i in tqdm(range(n_time)):\n",
    "        last_data_per_road = []\n",
    "        for j in range(20):\n",
    "            tmp_road = last_data[(last_data['id_jalan'] == j/20)]\n",
    "            tmp_road = tmp_road.reset_index(drop=True)\n",
    "            last_data_per_road.append(tmp_road)\n",
    "        current_test = df_test[(df_test['waktu_setempat'] == i)]\n",
    "        current_test = current_test.reset_index(drop=True)\n",
    "        tmp_pred_ = []\n",
    "        for index, row in current_test.iterrows():\n",
    "            predicted_data['id'].append(row['id'])\n",
    "            tmp_x2_test = np.array([row['id_jalan'], row['id_titik_mulai'], row['id_titik_akhir']])\n",
    "            tmp_x2_test = np.expand_dims(tmp_x2_test, axis=0)\n",
    "            idx_road = int(row['id_jalan']*20)\n",
    "            tmp_x1_test = last_data_per_road[idx_road]\n",
    "            n_x1 = len(tmp_x1_test)\n",
    "            tmp_x1_test = tmp_x1_test.drop(['waktu_setempat'], axis=1)\n",
    "            tmp_x1_test = tmp_x1_test.to_numpy().astype(np.float32)\n",
    "            if n_x1 > 0:\n",
    "                tmp_x2_test = [tmp_x2_test for aa in range(n_x1+1)]\n",
    "                tmp_x2_test = np.concatenate(tmp_x2_test, axis=0)\n",
    "                tmp_x1_test = np.concatenate((tmp_x1_test, no_prev), axis=0)\n",
    "            else:\n",
    "                tmp_x1_test = np.concatenate((tmp_x1_test, no_prev), axis=0)\n",
    "            # tmp_pred = []\n",
    "            # for i in range(n_x1):\n",
    "            # try:\n",
    "            tmp_pred = model.predict([np.expand_dims(tmp_x1_test, axis=1), np.expand_dims(tmp_x2_test, axis=1)], verbose=0, batch_size=n_x1).mean()\n",
    "            # except:\n",
    "            #     tmp_data__ = df[(df['id_jalan'] == row['id_jalan'])]\n",
    "            #     tmp_pred = tmp_data__['rerata_kecepatan'].mean()\n",
    "                # tmp_pred.append(tmp_pred2)\n",
    "            # tmp_pred = sum(tmp_pred)/len(tmp_pred)\n",
    "            predicted_data['rerata_kecepatan'].append(tmp_pred*max_avg)\n",
    "            tmp_pred_.append(tmp_pred*max_avg)\n",
    "        last_data = current_test[['waktu_setempat','id_jalan', 'id_titik_mulai', 'id_titik_akhir']]\n",
    "        last_data['rerata_kecepatan'] = tmp_pred_\n",
    "        tmp_pred_ = []\n",
    "    \n",
    "    return predicted_data\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = predict_test(df, df_test, model, max_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = predicted_data['id']\n",
    "predicted_data['id'] = np.asarray(tmp).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame.from_dict(predicted_data)\n",
    "subm = subm.sort_values(by=['id'])\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('submissionV2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBRegressor(n_jobs=-1, random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waktu_setempat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f'column: {col}; n_unique: {df[col].unique().shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
