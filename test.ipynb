{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to return the SMAPE value\n",
    "def smape(actual, predicted) -> float:\n",
    "  \n",
    "    # Convert actual and predicted to numpy\n",
    "    # array data type if not already\n",
    "    if not all([isinstance(actual, np.ndarray), \n",
    "                isinstance(predicted, np.ndarray)]):\n",
    "        actual, predicted = np.array(actual),\n",
    "        np.array(predicted)\n",
    "  \n",
    "    return round(\n",
    "        np.mean(\n",
    "            np.abs(predicted - actual) / \n",
    "            ((np.abs(predicted) + np.abs(actual))/2)\n",
    "        )*100, 6\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waktu_setempat</th>\n",
       "      <th>id_jalan</th>\n",
       "      <th>id_titik_mulai</th>\n",
       "      <th>id_titik_akhir</th>\n",
       "      <th>rerata_kecepatan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01 01:00:00+00:00</td>\n",
       "      <td>691007296</td>\n",
       "      <td>21390008</td>\n",
       "      <td>1425033102</td>\n",
       "      <td>29.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01 01:00:00+00:00</td>\n",
       "      <td>47010584</td>\n",
       "      <td>1677092762</td>\n",
       "      <td>579493410</td>\n",
       "      <td>46.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01 01:00:00+00:00</td>\n",
       "      <td>22932408</td>\n",
       "      <td>26486694</td>\n",
       "      <td>1930267566</td>\n",
       "      <td>36.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01 01:00:00+00:00</td>\n",
       "      <td>142479648</td>\n",
       "      <td>1111592522</td>\n",
       "      <td>3775231113</td>\n",
       "      <td>34.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01 01:00:00+00:00</td>\n",
       "      <td>8504977</td>\n",
       "      <td>5940503398</td>\n",
       "      <td>5940503394</td>\n",
       "      <td>38.336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              waktu_setempat   id_jalan  id_titik_mulai  id_titik_akhir  \\\n",
       "0  2020-02-01 01:00:00+00:00  691007296        21390008      1425033102   \n",
       "1  2020-02-01 01:00:00+00:00   47010584      1677092762       579493410   \n",
       "2  2020-02-01 01:00:00+00:00   22932408        26486694      1930267566   \n",
       "3  2020-02-01 01:00:00+00:00  142479648      1111592522      3775231113   \n",
       "4  2020-02-01 01:00:00+00:00    8504977      5940503398      5940503394   \n",
       "\n",
       "   rerata_kecepatan  \n",
       "0            29.126  \n",
       "1            46.576  \n",
       "2            36.587  \n",
       "3            34.063  \n",
       "4            38.336  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398648 entries, 0 to 398647\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   waktu_setempat    398648 non-null  object \n",
      " 1   id_jalan          398648 non-null  int64  \n",
      " 2   id_titik_mulai    398648 non-null  int64  \n",
      " 3   id_titik_akhir    398648 non-null  int64  \n",
      " 4   rerata_kecepatan  398648 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: waktu_setempat; n_unique: 527\n",
      "column: id_jalan; n_unique: 20\n",
      "column: id_titik_mulai; n_unique: 488\n",
      "column: id_titik_akhir; n_unique: 488\n",
      "column: rerata_kecepatan; n_unique: 29023\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f'column: {col}; n_unique: {df[col].unique().shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_titik = np.sort(np.unique(np.concatenate((df['id_titik_mulai'].unique(), df['id_titik_akhir'].unique()), axis=0)), axis=0, kind='mergesort')\n",
    "id_jalan = np.sort(df['id_jalan'].unique(), axis=0, kind='mergesort')\n",
    "waktu_setempat = np.sort(df['waktu_setempat'].unique(), axis=0, kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waktu_setempat</th>\n",
       "      <th>id_jalan</th>\n",
       "      <th>id_titik_mulai</th>\n",
       "      <th>id_titik_akhir</th>\n",
       "      <th>rerata_kecepatan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.209016</td>\n",
       "      <td>0.706967</td>\n",
       "      <td>0.401889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.774590</td>\n",
       "      <td>0.571721</td>\n",
       "      <td>0.642669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.272541</td>\n",
       "      <td>0.799180</td>\n",
       "      <td>0.504838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.674180</td>\n",
       "      <td>0.866803</td>\n",
       "      <td>0.470011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.954918</td>\n",
       "      <td>0.528971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   waktu_setempat  id_jalan  id_titik_mulai  id_titik_akhir  rerata_kecepatan\n",
       "0               0      0.95        0.209016        0.706967          0.401889\n",
       "1               0      0.60        0.774590        0.571721          0.642669\n",
       "2               0      0.40        0.272541        0.799180          0.504838\n",
       "3               0      0.80        0.674180        0.866803          0.470011\n",
       "4               0      0.35        0.956967        0.954918          0.528971"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['waktu_setempat','id_jalan', 'id_titik_mulai', 'id_titik_akhir']\n",
    "for col in cols:\n",
    "    tmp = []\n",
    "    for data in df[col].to_numpy():\n",
    "        if col == 'id_jalan':\n",
    "            idx = np.where(id_jalan == data)\n",
    "            idx = idx[0][0] / id_jalan.shape[0]\n",
    "        elif col == 'waktu_setempat':\n",
    "            idx = np.where(waktu_setempat == data)\n",
    "            idx = idx[0][0]\n",
    "        else:\n",
    "            idx = np.where(id_titik == data)\n",
    "            idx = idx[0][0] / id_titik.shape[0]\n",
    "        tmp.append(idx)\n",
    "    df[col] = tmp\n",
    "tmp = df['rerata_kecepatan'].to_numpy()\n",
    "max_avg = df['rerata_kecepatan'].max() * 1.2\n",
    "df['rerata_kecepatan'] = tmp / max_avg\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398648, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, window_len, forecast_len):\n",
    "    X = []\n",
    "    X2 = []\n",
    "    Y = []\n",
    "    no_prev = np.array([[-1, -1, -1, -1]]).astype(np.float32)\n",
    "    n_waktu_setempat = 527\n",
    "    n_jalan = 20\n",
    "    n_titik_mulai = 488\n",
    "    n_titik_akhir = 488\n",
    "    split_by_jalan = []\n",
    "    df = df.sort_values(by=['waktu_setempat', 'id_jalan', 'id_titik_mulai', 'id_titik_akhir'])\n",
    "    for i in range(n_jalan):\n",
    "        tmp = df[(df['id_jalan'] == i/20)]\n",
    "        tmp = tmp.reset_index(drop=True)\n",
    "        split_by_jalan.append(tmp)\n",
    "    for i in tqdm(range(n_jalan)):\n",
    "        data = split_by_jalan[i]\n",
    "        for t in range(n_waktu_setempat):\n",
    "            # for j in range(n_titik_mulai):\n",
    "            tmp = []\n",
    "            for k in range(window_len):\n",
    "                tmp2 = data[(data['waktu_setempat'] == t+k)]\n",
    "                tmp2 = tmp2.reset_index(drop=True)\n",
    "                tmp2 = tmp2.drop(['waktu_setempat'], axis=1)\n",
    "                tmp2 = tmp2.to_numpy().astype(np.float32)\n",
    "                tmp2 = np.concatenate((tmp2, no_prev), axis=0)\n",
    "                tmp.append(tmp2)\n",
    "            tmp2 = data[(data['waktu_setempat'] == t+window_len)]\n",
    "            tmp2 = tmp2.reset_index(drop=True)\n",
    "            tmp4 = tmp2['rerata_kecepatan'].to_numpy()\n",
    "            tmp2 = tmp2.drop(['waktu_setempat', 'rerata_kecepatan'], axis=1)\n",
    "            tmp2 = tmp2.to_numpy()\n",
    "            if window_len > 1:\n",
    "                tmp3 = list(itertools.product(*tmp))\n",
    "                \n",
    "            else:\n",
    "                tmp3 = tmp[0]\n",
    "            tmp3 = np.asarray(tmp3)\n",
    "            tmpX = []\n",
    "            tmpY = []\n",
    "            for _tmp in tmp3:\n",
    "                for idx, __tmp in enumerate(tmp2):\n",
    "                    _tmp = np.asarray(_tmp)\n",
    "                    __tmp = np.asarray(__tmp)\n",
    "                    __tmp2 = tmp4[idx]\n",
    "                    X.append(_tmp)\n",
    "                    X2.append(__tmp)\n",
    "                    Y.append(__tmp2)\n",
    "            # X.append(tmpX)\n",
    "            # Y.append(tmpY)\n",
    "            # X = X + tmpX\n",
    "            # Y = Y + tmpY\n",
    "\n",
    "    \n",
    "    # X = np.concatenate(X, axis=0)\n",
    "    # Y = np.concatenate(Y, axis=0)\n",
    "    X = np.asarray(X)\n",
    "    X2 = np.asarray(X2)\n",
    "    Y = np.asarray(Y)\n",
    "    return X, X2,  Y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp2 = tmp2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len=1\n",
    "forecast_len = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "X, X2, Y = create_dataset(df, window_len=window_len, forecast_len=forecast_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16645036, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16645036,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, x2_train, x2_test, y_train, y_test = train_test_split(X, X2, Y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder_block(past_inputs, future_inputs):\n",
    "    # Encoding the past\n",
    "    encoder = tf.keras.layers.LSTM(128, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(past_inputs)\n",
    "    state_h = state_h + tf.keras.layers.Dense(128, activation='relu')(state_h)\n",
    "    state_c = state_c + tf.keras.layers.Dense(128, activation='relu')(state_c)\n",
    "    \n",
    "    # x = tf.keras.layers.Dense(1)(future_inputs)\n",
    "    # \n",
    "    # Combining future inputs with recurrent branch output\n",
    "    decoder_lstm = tf.keras.layers.LSTM(128, return_sequences=True)\n",
    "    x = decoder_lstm(future_inputs,\n",
    "                    initial_state=[state_h, state_c])\n",
    "    return x\n",
    "\n",
    "past_inputs = tf.keras.Input(\n",
    "    shape=(window_len, 4), name='past_inputs')\n",
    "future_inputs = tf.keras.Input(\n",
    "        shape=(forecast_len, 3), name='future_inputs')\n",
    "\n",
    "x_1 = encoder_decoder_block(past_inputs, future_inputs)\n",
    "x = tf.keras.layers.Dense(4, activation='linear')(x_1) + past_inputs\n",
    "x = tf.keras.layers.ReLU()(x)\n",
    "x = encoder_decoder_block(x, future_inputs)\n",
    "x_2 = tf.keras.layers.Dense(256, activation='relu')(future_inputs)\n",
    "x = tf.keras.layers.Concatenate(axis=2)([x, x_1, x_2])\n",
    "x_1 = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x_1)\n",
    "x = tf.keras.layers.Concatenate(axis=1)([x, x_1])\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "output = tf.keras.layers.LeakyReLU(alpha=1e-5, name='outputs')(output)\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[past_inputs, future_inputs], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " past_inputs (InputLayer)    [(None, 1, 4)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 128),                68096     ['past_inputs[0][0]']         \n",
      "                              (None, 128),                                                        \n",
      "                              (None, 128)]                                                        \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  16512     ['lstm[0][1]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  16512     ['lstm[0][2]']                \n",
      "                                                                                                  \n",
      " future_inputs (InputLayer)  [(None, 1, 3)]               0         []                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 128)                  0         ['lstm[0][1]',                \n",
      " Lambda)                                                             'dense[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 128)                  0         ['lstm[0][2]',                \n",
      " OpLambda)                                                           'dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 1, 128)               67584     ['future_inputs[0][0]',       \n",
      "                                                                     'tf.__operators__.add[0][0]',\n",
      "                                                                     'tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 128)                  0         ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  16512     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  33024     ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    257       ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " outputs (LeakyReLU)         (None, 1)                    0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 218497 (853.50 KB)\n",
      "Trainable params: 218497 (853.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "past_inputs = tf.keras.Input(\n",
    "    shape=(window_len, 4), name='past_inputs')\n",
    "# Encoding the past\n",
    "encoder = tf.keras.layers.LSTM(128, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(past_inputs)\n",
    "state_h = state_h + tf.keras.layers.Dense(128, activation='relu')(state_h)\n",
    "state_c = state_c + tf.keras.layers.Dense(128, activation='relu')(state_c)\n",
    "future_inputs = tf.keras.Input(\n",
    "    shape=(forecast_len, 3), name='future_inputs')\n",
    "# x = tf.keras.layers.Dense(1)(future_inputs)\n",
    "# \n",
    "# Combining future inputs with recurrent branch output\n",
    "decoder_lstm = tf.keras.layers.LSTM(128, return_sequences=True)\n",
    "x = decoder_lstm(future_inputs,\n",
    "                 initial_state=[state_h, state_c])\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "output = tf.keras.layers.LeakyReLU(alpha=1e-5, name='outputs')(output)\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[past_inputs, future_inputs], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def smape_loss(y_true, y_pred):\n",
    "    epsilon = 0.1\n",
    "    summ = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
    "    smape = K.abs(y_pred - y_true) / summ * 2.0\n",
    "    return smape\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "loss = tf.keras.losses.MeanAbsoluteError()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[\"mae\", 'mse', 'mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20807/20807 [==============================] - 232s 11ms/step - loss: 0.0615 - mae: 0.0615 - mse: 0.0075 - mean_absolute_percentage_error: 17.5042 - val_loss: 0.0580 - val_mae: 0.0580 - val_mse: 0.0068 - val_mean_absolute_percentage_error: 16.4228\n",
      "Epoch 2/20\n",
      "20807/20807 [==============================] - 205s 10ms/step - loss: 0.0567 - mae: 0.0567 - mse: 0.0064 - mean_absolute_percentage_error: 15.7943 - val_loss: 0.0567 - val_mae: 0.0567 - val_mse: 0.0062 - val_mean_absolute_percentage_error: 15.5452\n",
      "Epoch 3/20\n",
      "20807/20807 [==============================] - 202s 10ms/step - loss: 0.0556 - mae: 0.0556 - mse: 0.0062 - mean_absolute_percentage_error: 15.4490 - val_loss: 0.0557 - val_mae: 0.0557 - val_mse: 0.0060 - val_mean_absolute_percentage_error: 15.0701\n",
      "Epoch 4/20\n",
      "20807/20807 [==============================] - 202s 10ms/step - loss: 0.0550 - mae: 0.0550 - mse: 0.0060 - mean_absolute_percentage_error: 15.2481 - val_loss: 0.0546 - val_mae: 0.0546 - val_mse: 0.0060 - val_mean_absolute_percentage_error: 15.1815\n",
      "Epoch 5/20\n",
      "20807/20807 [==============================] - 190s 9ms/step - loss: 0.0545 - mae: 0.0545 - mse: 0.0060 - mean_absolute_percentage_error: 15.1193 - val_loss: 0.0545 - val_mae: 0.0545 - val_mse: 0.0061 - val_mean_absolute_percentage_error: 15.2978\n",
      "Epoch 6/20\n",
      "20807/20807 [==============================] - 193s 9ms/step - loss: 0.0541 - mae: 0.0541 - mse: 0.0059 - mean_absolute_percentage_error: 14.9950 - val_loss: 0.0539 - val_mae: 0.0539 - val_mse: 0.0059 - val_mean_absolute_percentage_error: 15.0629\n",
      "Epoch 7/20\n",
      "20807/20807 [==============================] - 196s 9ms/step - loss: 0.0538 - mae: 0.0538 - mse: 0.0058 - mean_absolute_percentage_error: 14.8866 - val_loss: 0.0536 - val_mae: 0.0536 - val_mse: 0.0057 - val_mean_absolute_percentage_error: 14.7141\n",
      "Epoch 8/20\n",
      "20807/20807 [==============================] - 193s 9ms/step - loss: 0.0535 - mae: 0.0535 - mse: 0.0057 - mean_absolute_percentage_error: 14.7795 - val_loss: 0.0535 - val_mae: 0.0535 - val_mse: 0.0057 - val_mean_absolute_percentage_error: 14.6838\n",
      "Epoch 9/20\n",
      "20807/20807 [==============================] - 191s 9ms/step - loss: 0.0532 - mae: 0.0532 - mse: 0.0057 - mean_absolute_percentage_error: 14.6814 - val_loss: 0.0533 - val_mae: 0.0533 - val_mse: 0.0056 - val_mean_absolute_percentage_error: 14.4274\n",
      "Epoch 10/20\n",
      "20807/20807 [==============================] - 192s 9ms/step - loss: 0.0529 - mae: 0.0529 - mse: 0.0056 - mean_absolute_percentage_error: 14.6054 - val_loss: 0.0532 - val_mae: 0.0532 - val_mse: 0.0056 - val_mean_absolute_percentage_error: 14.5082\n",
      "Epoch 11/20\n",
      "20807/20807 [==============================] - 192s 9ms/step - loss: 0.0527 - mae: 0.0527 - mse: 0.0056 - mean_absolute_percentage_error: 14.5432 - val_loss: 0.0528 - val_mae: 0.0528 - val_mse: 0.0057 - val_mean_absolute_percentage_error: 14.6712\n",
      "Epoch 12/20\n",
      "20807/20807 [==============================] - 203s 10ms/step - loss: 0.0526 - mae: 0.0526 - mse: 0.0056 - mean_absolute_percentage_error: 14.4888 - val_loss: 0.0525 - val_mae: 0.0525 - val_mse: 0.0056 - val_mean_absolute_percentage_error: 14.5300\n",
      "Epoch 13/20\n",
      "20807/20807 [==============================] - 279s 13ms/step - loss: 0.0524 - mae: 0.0524 - mse: 0.0055 - mean_absolute_percentage_error: 14.4420 - val_loss: 0.0521 - val_mae: 0.0521 - val_mse: 0.0056 - val_mean_absolute_percentage_error: 14.4753\n",
      "Epoch 14/20\n",
      "20807/20807 [==============================] - 305s 15ms/step - loss: 0.0523 - mae: 0.0523 - mse: 0.0055 - mean_absolute_percentage_error: 14.4088 - val_loss: 0.0522 - val_mae: 0.0522 - val_mse: 0.0056 - val_mean_absolute_percentage_error: 14.5616\n",
      "Epoch 15/20\n",
      "20807/20807 [==============================] - 291s 14ms/step - loss: 0.0522 - mae: 0.0522 - mse: 0.0055 - mean_absolute_percentage_error: 14.3922 - val_loss: 0.0522 - val_mae: 0.0522 - val_mse: 0.0056 - val_mean_absolute_percentage_error: 14.5111\n",
      "Epoch 16/20\n",
      "20807/20807 [==============================] - 307s 15ms/step - loss: 0.0521 - mae: 0.0521 - mse: 0.0055 - mean_absolute_percentage_error: 14.3402 - val_loss: 0.0521 - val_mae: 0.0521 - val_mse: 0.0054 - val_mean_absolute_percentage_error: 14.2197\n",
      "Epoch 17/20\n",
      "20807/20807 [==============================] - 302s 15ms/step - loss: 0.0520 - mae: 0.0520 - mse: 0.0055 - mean_absolute_percentage_error: 14.3204 - val_loss: 0.0516 - val_mae: 0.0516 - val_mse: 0.0054 - val_mean_absolute_percentage_error: 14.1844\n",
      "Epoch 18/20\n",
      "20807/20807 [==============================] - 298s 14ms/step - loss: 0.0519 - mae: 0.0519 - mse: 0.0055 - mean_absolute_percentage_error: 14.2826 - val_loss: 0.0518 - val_mae: 0.0518 - val_mse: 0.0054 - val_mean_absolute_percentage_error: 14.1573\n",
      "Epoch 19/20\n",
      "20807/20807 [==============================] - 301s 14ms/step - loss: 0.0517 - mae: 0.0517 - mse: 0.0054 - mean_absolute_percentage_error: 14.2181 - val_loss: 0.0517 - val_mae: 0.0517 - val_mse: 0.0054 - val_mean_absolute_percentage_error: 14.2267\n",
      "Epoch 20/20\n",
      "20807/20807 [==============================] - 315s 15ms/step - loss: 0.0516 - mae: 0.0516 - mse: 0.0054 - mean_absolute_percentage_error: 14.1861 - val_loss: 0.0520 - val_mae: 0.0520 - val_mse: 0.0055 - val_mean_absolute_percentage_error: 14.4323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x299b603d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([np.expand_dims(x1_train, axis=1), np.expand_dims(x2_train, axis=1)], y_train, epochs=20, validation_split=0.2, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "626/626 [==============================] - 6s 9ms/step\n",
      "test_data: 11.779328\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "tmpx1 = []\n",
    "tmpx2 = []\n",
    "for idx, (x1, x2) in enumerate(zip(np.expand_dims(x1_test, axis=1), np.expand_dims(x2_test, axis=1))):\n",
    "    tmpx1.append(x1)\n",
    "    tmpx2.append(x2)\n",
    "    if (idx+1) % 2048000 == 0 or (idx+1) == len(x1_test):\n",
    "        tmpx1 = np.asarray(tmpx1)\n",
    "        tmpx2 = np.asarray(tmpx2)\n",
    "        tmp = model.predict([tmpx1, tmpx2], batch_size=2048)\n",
    "        tmp = np.asarray(tmp).astype(np.float32)\n",
    "        pred.append(tmp)\n",
    "        tmpx1 = []\n",
    "        tmpx2 = []\n",
    "pred = np.concatenate(pred, axis=0)\n",
    "pred = pred.flatten()\n",
    "print(f'test_data: {smape(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 46s 23ms/step\n",
      "1251/1251 [==============================] - 26s 21ms/step\n",
      "train_data: 11.767992\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "tmpx1 = []\n",
    "tmpx2 = []\n",
    "for idx, (x1, x2) in enumerate(zip(np.expand_dims(x1_train, axis=1), np.expand_dims(x2_train, axis=1))):\n",
    "    tmpx1.append(x1)\n",
    "    tmpx2.append(x2)\n",
    "    if (idx+1) % (2*4096000) == 0 or (idx+1) == len(x1_train):\n",
    "        tmpx1 = np.asarray(tmpx1)\n",
    "        tmpx2 = np.asarray(tmpx2)\n",
    "        tmp = model.predict([tmpx1, tmpx2], batch_size=4096)\n",
    "        tmp = np.asarray(tmp).astype(np.float32)\n",
    "        pred.append(tmp)\n",
    "        tmpx1 = []\n",
    "        tmpx2 = []\n",
    "pred = np.concatenate(pred, axis=0)\n",
    "pred = pred.flatten()\n",
    "print(f'train_data: {smape(y_train, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44399634"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([np.expand_dims(x1_train, axis=1)[0:5], np.expand_dims(x2_train, axis=1)[0:5]]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelV2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelV2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"modelV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>waktu_setempat</th>\n",
       "      <th>id_jalan</th>\n",
       "      <th>id_titik_mulai</th>\n",
       "      <th>id_titik_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>4004732</td>\n",
       "      <td>32046542</td>\n",
       "      <td>6454026544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>182210371</td>\n",
       "      <td>1314925464</td>\n",
       "      <td>1314925496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>22932408</td>\n",
       "      <td>1482086782</td>\n",
       "      <td>26481020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>182210371</td>\n",
       "      <td>3892883</td>\n",
       "      <td>267337489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>66924592</td>\n",
       "      <td>266041030</td>\n",
       "      <td>2592978110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             waktu_setempat   id_jalan  id_titik_mulai  id_titik_akhir\n",
       "0   0  2020-02-23 00:00:00+00:00    4004732        32046542      6454026544\n",
       "1   1  2020-02-23 00:00:00+00:00  182210371      1314925464      1314925496\n",
       "2   2  2020-02-23 00:00:00+00:00   22932408      1482086782        26481020\n",
       "3   3  2020-02-23 00:00:00+00:00  182210371         3892883       267337489\n",
       "4   4  2020-02-23 00:00:00+00:00   66924592       266041030      2592978110"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>waktu_setempat</th>\n",
       "      <th>id_jalan</th>\n",
       "      <th>id_titik_mulai</th>\n",
       "      <th>id_titik_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.313525</td>\n",
       "      <td>0.997951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.700820</td>\n",
       "      <td>0.702869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.719262</td>\n",
       "      <td>0.268443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.497951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.493852</td>\n",
       "      <td>0.836066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  waktu_setempat  id_jalan  id_titik_mulai  id_titik_akhir\n",
       "0   0               0      0.15        0.313525        0.997951\n",
       "1   1               0      0.90        0.700820        0.702869\n",
       "2   2               0      0.40        0.719262        0.268443\n",
       "3   3               0      0.90        0.139344        0.497951\n",
       "4   4               0      0.70        0.493852        0.836066"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['waktu_setempat','id_jalan', 'id_titik_mulai', 'id_titik_akhir']\n",
    "waktu_setempat_test = np.sort(df_test['waktu_setempat'].unique(), axis=0, kind='mergesort')\n",
    "for col in cols:\n",
    "    tmp = []\n",
    "    for data in df_test[col].to_numpy():\n",
    "        if col == 'id_jalan':\n",
    "            idx = np.where(id_jalan == data)\n",
    "            idx = idx[0][0] / id_jalan.shape[0]\n",
    "        elif col == 'waktu_setempat':\n",
    "            idx = np.where(waktu_setempat_test == data)\n",
    "            idx = idx[0][0]\n",
    "        else:\n",
    "            idx = np.where(id_titik == data)\n",
    "            idx = idx[0][0] / id_titik.shape[0]\n",
    "        tmp.append(idx)\n",
    "    df_test[col] = tmp\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(waktu_setempat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(df, df_test, model, max_avg):\n",
    "    last_data = df[(df['waktu_setempat'] == 526)]\n",
    "    last_data = last_data.reset_index(drop=True)\n",
    "    n_time = 168\n",
    "    predicted_data = {'id':[], 'rerata_kecepatan':[]}\n",
    "    no_prev = np.array([[-1, -1, -1, -1]]).astype(np.float32)\n",
    "    for i in tqdm(range(n_time)):\n",
    "        last_data_per_road = []\n",
    "        for j in range(20):\n",
    "            tmp_road = last_data[(last_data['id_jalan'] == j/20)]\n",
    "            tmp_road = tmp_road.reset_index(drop=True)\n",
    "            last_data_per_road.append(tmp_road)\n",
    "        current_test = df_test[(df_test['waktu_setempat'] == i)]\n",
    "        current_test = current_test.reset_index(drop=True)\n",
    "        tmp_pred_ = []\n",
    "        for index, row in current_test.iterrows():\n",
    "            predicted_data['id'].append(row['id'])\n",
    "            tmp_x2_test = np.array([row['id_jalan'], row['id_titik_mulai'], row['id_titik_akhir']])\n",
    "            tmp_x2_test = np.expand_dims(tmp_x2_test, axis=0)\n",
    "            idx_road = int(row['id_jalan']*20)\n",
    "            tmp_x1_test = last_data_per_road[idx_road]\n",
    "            n_x1 = len(tmp_x1_test)\n",
    "            tmp_x1_test = tmp_x1_test.drop(['waktu_setempat'], axis=1)\n",
    "            tmp_x1_test = tmp_x1_test.to_numpy().astype(np.float32)\n",
    "            if n_x1 > 0:\n",
    "                tmp_x2_test = [tmp_x2_test for aa in range(n_x1+1)]\n",
    "                tmp_x2_test = np.concatenate(tmp_x2_test, axis=0)\n",
    "                tmp_x1_test = np.concatenate((tmp_x1_test, no_prev), axis=0)\n",
    "            else:\n",
    "                tmp_x1_test = np.concatenate((tmp_x1_test, no_prev), axis=0)\n",
    "            # tmp_pred = []\n",
    "            # for i in range(n_x1):\n",
    "            # try:\n",
    "            tmp_pred = model.predict([np.expand_dims(tmp_x1_test, axis=1), np.expand_dims(tmp_x2_test, axis=1)], verbose=0, batch_size=n_x1).mean()\n",
    "            # except:\n",
    "            #     tmp_data__ = df[(df['id_jalan'] == row['id_jalan'])]\n",
    "            #     tmp_pred = tmp_data__['rerata_kecepatan'].mean()\n",
    "                # tmp_pred.append(tmp_pred2)\n",
    "            # tmp_pred = sum(tmp_pred)/len(tmp_pred)\n",
    "            predicted_data['rerata_kecepatan'].append(tmp_pred*max_avg)\n",
    "            tmp_pred_.append(tmp_pred*max_avg)\n",
    "        last_data = current_test[['waktu_setempat','id_jalan', 'id_titik_mulai', 'id_titik_akhir']]\n",
    "        last_data['rerata_kecepatan'] = tmp_pred_\n",
    "        tmp_pred_ = []\n",
    "    \n",
    "    return predicted_data\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [1:03:37<00:00, 22.72s/it]\n"
     ]
    }
   ],
   "source": [
    "predicted_data = predict_test(df, df_test, model, max_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = predicted_data['id']\n",
    "predicted_data['id'] = np.asarray(tmp).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rerata_kecepatan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41.504017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.519714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>34.982294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40.739993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32.622729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rerata_kecepatan\n",
       "0   0         41.504017\n",
       "1   1         41.519714\n",
       "2   2         34.982294\n",
       "3   3         40.739993\n",
       "4   4         32.622729"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.DataFrame.from_dict(predicted_data)\n",
    "subm = subm.sort_values(by=['id'])\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "subm.to_csv('submissionV2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgboost.XGBRegressor(n_jobs=-1, random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.29272 , 46.12336 , 35.993378, ..., 35.50384 , 33.308434,\n",
       "       37.70065 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-02-01 01:00:00+00:00', '2020-02-01 02:00:00+00:00',\n",
       "       '2020-02-01 03:00:00+00:00', '2020-02-01 04:00:00+00:00',\n",
       "       '2020-02-01 05:00:00+00:00', '2020-02-01 06:00:00+00:00',\n",
       "       '2020-02-01 07:00:00+00:00', '2020-02-01 08:00:00+00:00',\n",
       "       '2020-02-01 09:00:00+00:00', '2020-02-01 10:00:00+00:00',\n",
       "       '2020-02-01 11:00:00+00:00', '2020-02-01 12:00:00+00:00',\n",
       "       '2020-02-01 13:00:00+00:00', '2020-02-01 14:00:00+00:00',\n",
       "       '2020-02-01 15:00:00+00:00', '2020-02-01 16:00:00+00:00',\n",
       "       '2020-02-01 17:00:00+00:00', '2020-02-01 18:00:00+00:00',\n",
       "       '2020-02-01 19:00:00+00:00', '2020-02-01 20:00:00+00:00',\n",
       "       '2020-02-01 21:00:00+00:00', '2020-02-01 22:00:00+00:00',\n",
       "       '2020-02-01 23:00:00+00:00', '2020-02-02 00:00:00+00:00',\n",
       "       '2020-02-02 01:00:00+00:00', '2020-02-02 02:00:00+00:00',\n",
       "       '2020-02-02 03:00:00+00:00', '2020-02-02 04:00:00+00:00',\n",
       "       '2020-02-02 05:00:00+00:00', '2020-02-02 06:00:00+00:00',\n",
       "       '2020-02-02 07:00:00+00:00', '2020-02-02 08:00:00+00:00',\n",
       "       '2020-02-02 09:00:00+00:00', '2020-02-02 10:00:00+00:00',\n",
       "       '2020-02-02 11:00:00+00:00', '2020-02-02 12:00:00+00:00',\n",
       "       '2020-02-02 13:00:00+00:00', '2020-02-02 14:00:00+00:00',\n",
       "       '2020-02-02 15:00:00+00:00', '2020-02-02 16:00:00+00:00',\n",
       "       '2020-02-02 17:00:00+00:00', '2020-02-02 18:00:00+00:00',\n",
       "       '2020-02-02 19:00:00+00:00', '2020-02-02 20:00:00+00:00',\n",
       "       '2020-02-02 21:00:00+00:00', '2020-02-02 22:00:00+00:00',\n",
       "       '2020-02-02 23:00:00+00:00', '2020-02-03 00:00:00+00:00',\n",
       "       '2020-02-03 01:00:00+00:00', '2020-02-03 02:00:00+00:00',\n",
       "       '2020-02-03 03:00:00+00:00', '2020-02-03 04:00:00+00:00',\n",
       "       '2020-02-03 05:00:00+00:00', '2020-02-03 06:00:00+00:00',\n",
       "       '2020-02-03 07:00:00+00:00', '2020-02-03 08:00:00+00:00',\n",
       "       '2020-02-03 09:00:00+00:00', '2020-02-03 10:00:00+00:00',\n",
       "       '2020-02-03 11:00:00+00:00', '2020-02-03 12:00:00+00:00',\n",
       "       '2020-02-03 13:00:00+00:00', '2020-02-03 14:00:00+00:00',\n",
       "       '2020-02-03 15:00:00+00:00', '2020-02-03 16:00:00+00:00',\n",
       "       '2020-02-03 17:00:00+00:00', '2020-02-03 18:00:00+00:00',\n",
       "       '2020-02-03 19:00:00+00:00', '2020-02-03 20:00:00+00:00',\n",
       "       '2020-02-03 21:00:00+00:00', '2020-02-03 22:00:00+00:00',\n",
       "       '2020-02-03 23:00:00+00:00', '2020-02-04 00:00:00+00:00',\n",
       "       '2020-02-04 01:00:00+00:00', '2020-02-04 02:00:00+00:00',\n",
       "       '2020-02-04 03:00:00+00:00', '2020-02-04 04:00:00+00:00',\n",
       "       '2020-02-04 05:00:00+00:00', '2020-02-04 06:00:00+00:00',\n",
       "       '2020-02-04 07:00:00+00:00', '2020-02-04 08:00:00+00:00',\n",
       "       '2020-02-04 09:00:00+00:00', '2020-02-04 10:00:00+00:00',\n",
       "       '2020-02-04 11:00:00+00:00', '2020-02-04 12:00:00+00:00',\n",
       "       '2020-02-04 13:00:00+00:00', '2020-02-04 14:00:00+00:00',\n",
       "       '2020-02-04 15:00:00+00:00', '2020-02-04 16:00:00+00:00',\n",
       "       '2020-02-04 17:00:00+00:00', '2020-02-04 18:00:00+00:00',\n",
       "       '2020-02-04 19:00:00+00:00', '2020-02-04 20:00:00+00:00',\n",
       "       '2020-02-04 21:00:00+00:00', '2020-02-04 22:00:00+00:00',\n",
       "       '2020-02-04 23:00:00+00:00', '2020-02-05 00:00:00+00:00',\n",
       "       '2020-02-05 01:00:00+00:00', '2020-02-05 02:00:00+00:00',\n",
       "       '2020-02-05 03:00:00+00:00', '2020-02-05 04:00:00+00:00',\n",
       "       '2020-02-05 05:00:00+00:00', '2020-02-05 06:00:00+00:00',\n",
       "       '2020-02-05 07:00:00+00:00', '2020-02-05 08:00:00+00:00',\n",
       "       '2020-02-05 09:00:00+00:00', '2020-02-05 10:00:00+00:00',\n",
       "       '2020-02-05 11:00:00+00:00', '2020-02-05 12:00:00+00:00',\n",
       "       '2020-02-05 13:00:00+00:00', '2020-02-05 14:00:00+00:00',\n",
       "       '2020-02-05 15:00:00+00:00', '2020-02-05 16:00:00+00:00',\n",
       "       '2020-02-05 17:00:00+00:00', '2020-02-05 18:00:00+00:00',\n",
       "       '2020-02-05 19:00:00+00:00', '2020-02-05 20:00:00+00:00',\n",
       "       '2020-02-05 21:00:00+00:00', '2020-02-05 22:00:00+00:00',\n",
       "       '2020-02-05 23:00:00+00:00', '2020-02-06 00:00:00+00:00',\n",
       "       '2020-02-06 01:00:00+00:00', '2020-02-06 02:00:00+00:00',\n",
       "       '2020-02-06 03:00:00+00:00', '2020-02-06 04:00:00+00:00',\n",
       "       '2020-02-06 05:00:00+00:00', '2020-02-06 06:00:00+00:00',\n",
       "       '2020-02-06 07:00:00+00:00', '2020-02-06 08:00:00+00:00',\n",
       "       '2020-02-06 09:00:00+00:00', '2020-02-06 10:00:00+00:00',\n",
       "       '2020-02-06 11:00:00+00:00', '2020-02-06 12:00:00+00:00',\n",
       "       '2020-02-06 13:00:00+00:00', '2020-02-06 14:00:00+00:00',\n",
       "       '2020-02-06 15:00:00+00:00', '2020-02-06 16:00:00+00:00',\n",
       "       '2020-02-06 17:00:00+00:00', '2020-02-06 18:00:00+00:00',\n",
       "       '2020-02-06 19:00:00+00:00', '2020-02-06 20:00:00+00:00',\n",
       "       '2020-02-06 21:00:00+00:00', '2020-02-06 22:00:00+00:00',\n",
       "       '2020-02-06 23:00:00+00:00', '2020-02-07 00:00:00+00:00',\n",
       "       '2020-02-07 01:00:00+00:00', '2020-02-07 02:00:00+00:00',\n",
       "       '2020-02-07 03:00:00+00:00', '2020-02-07 04:00:00+00:00',\n",
       "       '2020-02-07 05:00:00+00:00', '2020-02-07 06:00:00+00:00',\n",
       "       '2020-02-07 07:00:00+00:00', '2020-02-07 08:00:00+00:00',\n",
       "       '2020-02-07 09:00:00+00:00', '2020-02-07 10:00:00+00:00',\n",
       "       '2020-02-07 11:00:00+00:00', '2020-02-07 12:00:00+00:00',\n",
       "       '2020-02-07 13:00:00+00:00', '2020-02-07 14:00:00+00:00',\n",
       "       '2020-02-07 15:00:00+00:00', '2020-02-07 16:00:00+00:00',\n",
       "       '2020-02-07 17:00:00+00:00', '2020-02-07 18:00:00+00:00',\n",
       "       '2020-02-07 19:00:00+00:00', '2020-02-07 20:00:00+00:00',\n",
       "       '2020-02-07 21:00:00+00:00', '2020-02-07 22:00:00+00:00',\n",
       "       '2020-02-07 23:00:00+00:00', '2020-02-08 00:00:00+00:00',\n",
       "       '2020-02-08 01:00:00+00:00', '2020-02-08 02:00:00+00:00',\n",
       "       '2020-02-08 03:00:00+00:00', '2020-02-08 04:00:00+00:00',\n",
       "       '2020-02-08 05:00:00+00:00', '2020-02-08 06:00:00+00:00',\n",
       "       '2020-02-08 07:00:00+00:00', '2020-02-08 08:00:00+00:00',\n",
       "       '2020-02-08 09:00:00+00:00', '2020-02-08 10:00:00+00:00',\n",
       "       '2020-02-08 11:00:00+00:00', '2020-02-08 12:00:00+00:00',\n",
       "       '2020-02-08 13:00:00+00:00', '2020-02-08 14:00:00+00:00',\n",
       "       '2020-02-08 15:00:00+00:00', '2020-02-08 16:00:00+00:00',\n",
       "       '2020-02-08 17:00:00+00:00', '2020-02-08 18:00:00+00:00',\n",
       "       '2020-02-08 19:00:00+00:00', '2020-02-08 20:00:00+00:00',\n",
       "       '2020-02-08 21:00:00+00:00', '2020-02-08 22:00:00+00:00',\n",
       "       '2020-02-08 23:00:00+00:00', '2020-02-09 00:00:00+00:00',\n",
       "       '2020-02-09 01:00:00+00:00', '2020-02-09 02:00:00+00:00',\n",
       "       '2020-02-09 03:00:00+00:00', '2020-02-09 04:00:00+00:00',\n",
       "       '2020-02-09 05:00:00+00:00', '2020-02-09 06:00:00+00:00',\n",
       "       '2020-02-09 07:00:00+00:00', '2020-02-09 08:00:00+00:00',\n",
       "       '2020-02-09 09:00:00+00:00', '2020-02-09 10:00:00+00:00',\n",
       "       '2020-02-09 11:00:00+00:00', '2020-02-09 12:00:00+00:00',\n",
       "       '2020-02-09 13:00:00+00:00', '2020-02-09 14:00:00+00:00',\n",
       "       '2020-02-09 15:00:00+00:00', '2020-02-09 16:00:00+00:00',\n",
       "       '2020-02-09 17:00:00+00:00', '2020-02-09 18:00:00+00:00',\n",
       "       '2020-02-09 19:00:00+00:00', '2020-02-09 20:00:00+00:00',\n",
       "       '2020-02-09 21:00:00+00:00', '2020-02-09 22:00:00+00:00',\n",
       "       '2020-02-09 23:00:00+00:00', '2020-02-10 00:00:00+00:00',\n",
       "       '2020-02-10 01:00:00+00:00', '2020-02-10 02:00:00+00:00',\n",
       "       '2020-02-10 03:00:00+00:00', '2020-02-10 04:00:00+00:00',\n",
       "       '2020-02-10 05:00:00+00:00', '2020-02-10 06:00:00+00:00',\n",
       "       '2020-02-10 07:00:00+00:00', '2020-02-10 08:00:00+00:00',\n",
       "       '2020-02-10 09:00:00+00:00', '2020-02-10 10:00:00+00:00',\n",
       "       '2020-02-10 11:00:00+00:00', '2020-02-10 12:00:00+00:00',\n",
       "       '2020-02-10 13:00:00+00:00', '2020-02-10 14:00:00+00:00',\n",
       "       '2020-02-10 15:00:00+00:00', '2020-02-10 16:00:00+00:00',\n",
       "       '2020-02-10 17:00:00+00:00', '2020-02-10 18:00:00+00:00',\n",
       "       '2020-02-10 19:00:00+00:00', '2020-02-10 20:00:00+00:00',\n",
       "       '2020-02-10 21:00:00+00:00', '2020-02-10 22:00:00+00:00',\n",
       "       '2020-02-10 23:00:00+00:00', '2020-02-11 00:00:00+00:00',\n",
       "       '2020-02-11 01:00:00+00:00', '2020-02-11 02:00:00+00:00',\n",
       "       '2020-02-11 03:00:00+00:00', '2020-02-11 04:00:00+00:00',\n",
       "       '2020-02-11 05:00:00+00:00', '2020-02-11 06:00:00+00:00',\n",
       "       '2020-02-11 07:00:00+00:00', '2020-02-11 08:00:00+00:00',\n",
       "       '2020-02-11 09:00:00+00:00', '2020-02-11 10:00:00+00:00',\n",
       "       '2020-02-11 11:00:00+00:00', '2020-02-11 12:00:00+00:00',\n",
       "       '2020-02-11 13:00:00+00:00', '2020-02-11 14:00:00+00:00',\n",
       "       '2020-02-11 15:00:00+00:00', '2020-02-11 16:00:00+00:00',\n",
       "       '2020-02-11 17:00:00+00:00', '2020-02-11 18:00:00+00:00',\n",
       "       '2020-02-11 19:00:00+00:00', '2020-02-11 20:00:00+00:00',\n",
       "       '2020-02-11 21:00:00+00:00', '2020-02-11 22:00:00+00:00',\n",
       "       '2020-02-11 23:00:00+00:00', '2020-02-12 00:00:00+00:00',\n",
       "       '2020-02-12 01:00:00+00:00', '2020-02-12 02:00:00+00:00',\n",
       "       '2020-02-12 03:00:00+00:00', '2020-02-12 04:00:00+00:00',\n",
       "       '2020-02-12 05:00:00+00:00', '2020-02-12 06:00:00+00:00',\n",
       "       '2020-02-12 07:00:00+00:00', '2020-02-12 08:00:00+00:00',\n",
       "       '2020-02-12 09:00:00+00:00', '2020-02-12 10:00:00+00:00',\n",
       "       '2020-02-12 11:00:00+00:00', '2020-02-12 12:00:00+00:00',\n",
       "       '2020-02-12 13:00:00+00:00', '2020-02-12 14:00:00+00:00',\n",
       "       '2020-02-12 15:00:00+00:00', '2020-02-12 16:00:00+00:00',\n",
       "       '2020-02-12 17:00:00+00:00', '2020-02-12 18:00:00+00:00',\n",
       "       '2020-02-12 19:00:00+00:00', '2020-02-12 20:00:00+00:00',\n",
       "       '2020-02-12 21:00:00+00:00', '2020-02-12 22:00:00+00:00',\n",
       "       '2020-02-12 23:00:00+00:00', '2020-02-13 00:00:00+00:00',\n",
       "       '2020-02-13 01:00:00+00:00', '2020-02-13 02:00:00+00:00',\n",
       "       '2020-02-13 03:00:00+00:00', '2020-02-13 04:00:00+00:00',\n",
       "       '2020-02-13 05:00:00+00:00', '2020-02-13 06:00:00+00:00',\n",
       "       '2020-02-13 07:00:00+00:00', '2020-02-13 08:00:00+00:00',\n",
       "       '2020-02-13 09:00:00+00:00', '2020-02-13 10:00:00+00:00',\n",
       "       '2020-02-13 11:00:00+00:00', '2020-02-13 12:00:00+00:00',\n",
       "       '2020-02-13 13:00:00+00:00', '2020-02-13 14:00:00+00:00',\n",
       "       '2020-02-13 15:00:00+00:00', '2020-02-13 16:00:00+00:00',\n",
       "       '2020-02-13 17:00:00+00:00', '2020-02-13 18:00:00+00:00',\n",
       "       '2020-02-13 19:00:00+00:00', '2020-02-13 20:00:00+00:00',\n",
       "       '2020-02-13 21:00:00+00:00', '2020-02-13 22:00:00+00:00',\n",
       "       '2020-02-13 23:00:00+00:00', '2020-02-14 00:00:00+00:00',\n",
       "       '2020-02-14 01:00:00+00:00', '2020-02-14 02:00:00+00:00',\n",
       "       '2020-02-14 03:00:00+00:00', '2020-02-14 04:00:00+00:00',\n",
       "       '2020-02-14 05:00:00+00:00', '2020-02-14 06:00:00+00:00',\n",
       "       '2020-02-14 07:00:00+00:00', '2020-02-14 08:00:00+00:00',\n",
       "       '2020-02-14 09:00:00+00:00', '2020-02-14 10:00:00+00:00',\n",
       "       '2020-02-14 11:00:00+00:00', '2020-02-14 12:00:00+00:00',\n",
       "       '2020-02-14 13:00:00+00:00', '2020-02-14 14:00:00+00:00',\n",
       "       '2020-02-14 15:00:00+00:00', '2020-02-14 16:00:00+00:00',\n",
       "       '2020-02-14 17:00:00+00:00', '2020-02-14 18:00:00+00:00',\n",
       "       '2020-02-14 19:00:00+00:00', '2020-02-14 20:00:00+00:00',\n",
       "       '2020-02-14 21:00:00+00:00', '2020-02-14 22:00:00+00:00',\n",
       "       '2020-02-14 23:00:00+00:00', '2020-02-15 00:00:00+00:00',\n",
       "       '2020-02-15 01:00:00+00:00', '2020-02-15 02:00:00+00:00',\n",
       "       '2020-02-15 03:00:00+00:00', '2020-02-15 04:00:00+00:00',\n",
       "       '2020-02-15 05:00:00+00:00', '2020-02-15 06:00:00+00:00',\n",
       "       '2020-02-15 07:00:00+00:00', '2020-02-15 08:00:00+00:00',\n",
       "       '2020-02-15 09:00:00+00:00', '2020-02-15 10:00:00+00:00',\n",
       "       '2020-02-15 11:00:00+00:00', '2020-02-15 12:00:00+00:00',\n",
       "       '2020-02-15 13:00:00+00:00', '2020-02-15 14:00:00+00:00',\n",
       "       '2020-02-15 15:00:00+00:00', '2020-02-15 16:00:00+00:00',\n",
       "       '2020-02-15 17:00:00+00:00', '2020-02-15 18:00:00+00:00',\n",
       "       '2020-02-15 19:00:00+00:00', '2020-02-15 20:00:00+00:00',\n",
       "       '2020-02-15 21:00:00+00:00', '2020-02-15 22:00:00+00:00',\n",
       "       '2020-02-15 23:00:00+00:00', '2020-02-16 00:00:00+00:00',\n",
       "       '2020-02-16 01:00:00+00:00', '2020-02-16 02:00:00+00:00',\n",
       "       '2020-02-16 03:00:00+00:00', '2020-02-16 04:00:00+00:00',\n",
       "       '2020-02-16 05:00:00+00:00', '2020-02-16 06:00:00+00:00',\n",
       "       '2020-02-16 07:00:00+00:00', '2020-02-16 08:00:00+00:00',\n",
       "       '2020-02-16 09:00:00+00:00', '2020-02-16 10:00:00+00:00',\n",
       "       '2020-02-16 11:00:00+00:00', '2020-02-16 12:00:00+00:00',\n",
       "       '2020-02-16 13:00:00+00:00', '2020-02-16 14:00:00+00:00',\n",
       "       '2020-02-16 15:00:00+00:00', '2020-02-16 16:00:00+00:00',\n",
       "       '2020-02-16 17:00:00+00:00', '2020-02-16 18:00:00+00:00',\n",
       "       '2020-02-16 19:00:00+00:00', '2020-02-16 20:00:00+00:00',\n",
       "       '2020-02-16 21:00:00+00:00', '2020-02-16 22:00:00+00:00',\n",
       "       '2020-02-16 23:00:00+00:00', '2020-02-17 00:00:00+00:00',\n",
       "       '2020-02-17 01:00:00+00:00', '2020-02-17 02:00:00+00:00',\n",
       "       '2020-02-17 03:00:00+00:00', '2020-02-17 04:00:00+00:00',\n",
       "       '2020-02-17 05:00:00+00:00', '2020-02-17 06:00:00+00:00',\n",
       "       '2020-02-17 07:00:00+00:00', '2020-02-17 08:00:00+00:00',\n",
       "       '2020-02-17 09:00:00+00:00', '2020-02-17 10:00:00+00:00',\n",
       "       '2020-02-17 11:00:00+00:00', '2020-02-17 12:00:00+00:00',\n",
       "       '2020-02-17 13:00:00+00:00', '2020-02-17 14:00:00+00:00',\n",
       "       '2020-02-17 15:00:00+00:00', '2020-02-17 16:00:00+00:00',\n",
       "       '2020-02-17 17:00:00+00:00', '2020-02-17 18:00:00+00:00',\n",
       "       '2020-02-17 19:00:00+00:00', '2020-02-17 20:00:00+00:00',\n",
       "       '2020-02-17 21:00:00+00:00', '2020-02-17 22:00:00+00:00',\n",
       "       '2020-02-17 23:00:00+00:00', '2020-02-18 00:00:00+00:00',\n",
       "       '2020-02-18 01:00:00+00:00', '2020-02-18 02:00:00+00:00',\n",
       "       '2020-02-18 03:00:00+00:00', '2020-02-18 04:00:00+00:00',\n",
       "       '2020-02-18 05:00:00+00:00', '2020-02-18 06:00:00+00:00',\n",
       "       '2020-02-18 07:00:00+00:00', '2020-02-18 08:00:00+00:00',\n",
       "       '2020-02-18 09:00:00+00:00', '2020-02-18 10:00:00+00:00',\n",
       "       '2020-02-18 11:00:00+00:00', '2020-02-18 12:00:00+00:00',\n",
       "       '2020-02-18 13:00:00+00:00', '2020-02-18 14:00:00+00:00',\n",
       "       '2020-02-18 15:00:00+00:00', '2020-02-18 16:00:00+00:00',\n",
       "       '2020-02-18 17:00:00+00:00', '2020-02-18 18:00:00+00:00',\n",
       "       '2020-02-18 19:00:00+00:00', '2020-02-18 20:00:00+00:00',\n",
       "       '2020-02-18 21:00:00+00:00', '2020-02-18 22:00:00+00:00',\n",
       "       '2020-02-18 23:00:00+00:00', '2020-02-19 00:00:00+00:00',\n",
       "       '2020-02-19 01:00:00+00:00', '2020-02-19 02:00:00+00:00',\n",
       "       '2020-02-19 03:00:00+00:00', '2020-02-19 04:00:00+00:00',\n",
       "       '2020-02-19 05:00:00+00:00', '2020-02-19 06:00:00+00:00',\n",
       "       '2020-02-19 07:00:00+00:00', '2020-02-19 08:00:00+00:00',\n",
       "       '2020-02-19 09:00:00+00:00', '2020-02-19 10:00:00+00:00',\n",
       "       '2020-02-19 11:00:00+00:00', '2020-02-19 12:00:00+00:00',\n",
       "       '2020-02-19 13:00:00+00:00', '2020-02-19 14:00:00+00:00',\n",
       "       '2020-02-19 15:00:00+00:00', '2020-02-19 16:00:00+00:00',\n",
       "       '2020-02-19 17:00:00+00:00', '2020-02-19 18:00:00+00:00',\n",
       "       '2020-02-19 19:00:00+00:00', '2020-02-19 20:00:00+00:00',\n",
       "       '2020-02-19 21:00:00+00:00', '2020-02-19 22:00:00+00:00',\n",
       "       '2020-02-19 23:00:00+00:00', '2020-02-20 00:00:00+00:00',\n",
       "       '2020-02-20 01:00:00+00:00', '2020-02-20 02:00:00+00:00',\n",
       "       '2020-02-20 03:00:00+00:00', '2020-02-20 04:00:00+00:00',\n",
       "       '2020-02-20 05:00:00+00:00', '2020-02-20 06:00:00+00:00',\n",
       "       '2020-02-20 07:00:00+00:00', '2020-02-20 08:00:00+00:00',\n",
       "       '2020-02-20 09:00:00+00:00', '2020-02-20 10:00:00+00:00',\n",
       "       '2020-02-20 11:00:00+00:00', '2020-02-20 12:00:00+00:00',\n",
       "       '2020-02-20 13:00:00+00:00', '2020-02-20 14:00:00+00:00',\n",
       "       '2020-02-20 15:00:00+00:00', '2020-02-20 16:00:00+00:00',\n",
       "       '2020-02-20 17:00:00+00:00', '2020-02-20 18:00:00+00:00',\n",
       "       '2020-02-20 19:00:00+00:00', '2020-02-20 20:00:00+00:00',\n",
       "       '2020-02-20 21:00:00+00:00', '2020-02-20 22:00:00+00:00',\n",
       "       '2020-02-20 23:00:00+00:00', '2020-02-21 00:00:00+00:00',\n",
       "       '2020-02-21 01:00:00+00:00', '2020-02-21 02:00:00+00:00',\n",
       "       '2020-02-21 03:00:00+00:00', '2020-02-21 04:00:00+00:00',\n",
       "       '2020-02-21 05:00:00+00:00', '2020-02-21 06:00:00+00:00',\n",
       "       '2020-02-21 07:00:00+00:00', '2020-02-21 08:00:00+00:00',\n",
       "       '2020-02-21 09:00:00+00:00', '2020-02-21 10:00:00+00:00',\n",
       "       '2020-02-21 11:00:00+00:00', '2020-02-21 12:00:00+00:00',\n",
       "       '2020-02-21 13:00:00+00:00', '2020-02-21 14:00:00+00:00',\n",
       "       '2020-02-21 15:00:00+00:00', '2020-02-21 16:00:00+00:00',\n",
       "       '2020-02-21 17:00:00+00:00', '2020-02-21 18:00:00+00:00',\n",
       "       '2020-02-21 19:00:00+00:00', '2020-02-21 20:00:00+00:00',\n",
       "       '2020-02-21 21:00:00+00:00', '2020-02-21 22:00:00+00:00',\n",
       "       '2020-02-21 23:00:00+00:00', '2020-02-22 00:00:00+00:00',\n",
       "       '2020-02-22 01:00:00+00:00', '2020-02-22 02:00:00+00:00',\n",
       "       '2020-02-22 03:00:00+00:00', '2020-02-22 04:00:00+00:00',\n",
       "       '2020-02-22 05:00:00+00:00', '2020-02-22 06:00:00+00:00',\n",
       "       '2020-02-22 07:00:00+00:00', '2020-02-22 08:00:00+00:00',\n",
       "       '2020-02-22 09:00:00+00:00', '2020-02-22 10:00:00+00:00',\n",
       "       '2020-02-22 11:00:00+00:00', '2020-02-22 12:00:00+00:00',\n",
       "       '2020-02-22 13:00:00+00:00', '2020-02-22 14:00:00+00:00',\n",
       "       '2020-02-22 15:00:00+00:00', '2020-02-22 16:00:00+00:00',\n",
       "       '2020-02-22 17:00:00+00:00', '2020-02-22 18:00:00+00:00',\n",
       "       '2020-02-22 19:00:00+00:00', '2020-02-22 20:00:00+00:00',\n",
       "       '2020-02-22 21:00:00+00:00', '2020-02-22 22:00:00+00:00',\n",
       "       '2020-02-22 23:00:00+00:00'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waktu_setempat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>waktu_setempat</th>\n",
       "      <th>id_jalan</th>\n",
       "      <th>id_titik_mulai</th>\n",
       "      <th>id_titik_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>4004732</td>\n",
       "      <td>32046542</td>\n",
       "      <td>6454026544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>182210371</td>\n",
       "      <td>1314925464</td>\n",
       "      <td>1314925496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>22932408</td>\n",
       "      <td>1482086782</td>\n",
       "      <td>26481020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>182210371</td>\n",
       "      <td>3892883</td>\n",
       "      <td>267337489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-23 00:00:00+00:00</td>\n",
       "      <td>66924592</td>\n",
       "      <td>266041030</td>\n",
       "      <td>2592978110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             waktu_setempat   id_jalan  id_titik_mulai  id_titik_akhir\n",
       "0   0  2020-02-23 00:00:00+00:00    4004732        32046542      6454026544\n",
       "1   1  2020-02-23 00:00:00+00:00  182210371      1314925464      1314925496\n",
       "2   2  2020-02-23 00:00:00+00:00   22932408      1482086782        26481020\n",
       "3   3  2020-02-23 00:00:00+00:00  182210371         3892883       267337489\n",
       "4   4  2020-02-23 00:00:00+00:00   66924592       266041030      2592978110"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: id; n_unique: 127489\n",
      "column: waktu_setempat; n_unique: 168\n",
      "column: id_jalan; n_unique: 20\n",
      "column: id_titik_mulai; n_unique: 488\n",
      "column: id_titik_akhir; n_unique: 488\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f'column: {col}; n_unique: {df[col].unique().shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
